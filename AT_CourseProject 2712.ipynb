{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec37017",
   "metadata": {},
   "source": [
    "**Импорт библиотек**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62b27a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recommenders import MainRecommender\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07967386",
   "metadata": {},
   "source": [
    "Для решения задачи класс MainRecommender был улучшен (в сравнении с версией Baseline) - изменены параметры обучения модели и выбора кандидатов, добавлена возможность при инициализации класса указать параметр (метрику) по которой строится матрица."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5137be",
   "metadata": {},
   "source": [
    "**Функции**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c51c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_data(df_data, name_df):\n",
    "    print(name_df)\n",
    "    print(f\"Shape: {df_data.shape} Users: {df_data[USER_COL].nunique()} Items: {df_data[ITEM_COL].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6562bc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision_at_k(df_data, top_k):\n",
    "    for col_name in df_data.columns[2:]:\n",
    "        yield col_name, df_data.apply(lambda row: precision_at_k(row[col_name], row[ACTUAL_COL], k=top_k), axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a2b842",
   "metadata": {},
   "source": [
    "**Загрука и преподготовка данных**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97eef5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('retail_train.csv') #user-item data\n",
    "item_features = pd.read_csv('product.csv') #item data\n",
    "user_features = pd.read_csv('hh_demographic.csv') #user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265fa7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0dd4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем доп. метрики для обучения модели первого уровня\n",
    "data['log_quantity'] = np.log(data['quantity'])\n",
    "data['log_sales_value'] = np.log(data['sales_value'])\n",
    "data['log_quantity+1'] = np.log(data['quantity']+1)\n",
    "data['log_sales_value+1'] = np.log(data['sales_value']+1)\n",
    "data.loc[data['quantity']>0, 'boughten'] = 1\n",
    "data.loc[data['quantity']==0, 'boughten'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19810d82",
   "metadata": {},
   "source": [
    "Создание глобальных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971b91b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_COL = 'item_id'\n",
    "USER_COL = 'user_id'\n",
    "ACTUAL_COL = 'actual'\n",
    "\n",
    "# N = Neighbors\n",
    "N_PREDICT = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70709fc6",
   "metadata": {},
   "source": [
    "Разделение на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fcedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_MATCHER_WEEKS = 6\n",
    "VAL_RANKER_WEEKS = 3\n",
    "\n",
    "# берем данные для тренировки matching модели\n",
    "data_train_matcher = data[data['week_no'] < data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)]\n",
    "\n",
    "# берем данные для валидации matching модели\n",
    "data_val_matcher = data[(data['week_no'] >= data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (VAL_RANKER_WEEKS))]\n",
    "\n",
    "\n",
    "# берем данные для тренировки ranking модели\n",
    "data_train_ranker = data_val_matcher.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "\n",
    "# берем данные для теста ranking, matching модели\n",
    "data_val_ranker = data[data['week_no'] >= data['week_no'].max() - VAL_RANKER_WEEKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a63477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем объединенный сет данных для первого уровня (матчинга)\n",
    "df_join_train_matcher = pd.concat([data_train_matcher, data_val_matcher])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2cd2c8",
   "metadata": {},
   "source": [
    "Префильтрация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc955f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_popular = 11000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f7c408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 11001\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_matcher['item_id'].nunique()\n",
    "\n",
    "data_train_matcher = prefilter_items(data_train_matcher, item_features=item_features, take_n_popular=n_popular)\n",
    "\n",
    "n_items_after = data_train_matcher['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d46b8",
   "metadata": {},
   "source": [
    "Обработка холодного старта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d873aeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_matcher\n",
      "Shape: (784420, 18) Users: 1915 Items: 10995\n",
      "val_matcher\n",
      "Shape: (163261, 17) Users: 1915 Items: 27118\n",
      "train_ranker\n",
      "Shape: (163261, 17) Users: 1915 Items: 27118\n",
      "val_ranker\n",
      "Shape: (115989, 17) Users: 1915 Items: 24042\n"
     ]
    }
   ],
   "source": [
    "# ищем общих пользователей\n",
    "common_users = list(set(data_train_matcher.user_id.values)&(set(data_val_matcher.user_id.values))&set(data_val_ranker.user_id.values))\n",
    "\n",
    "# оставляем общих пользователей\n",
    "data_train_matcher = data_train_matcher[data_train_matcher.user_id.isin(common_users)]\n",
    "data_val_matcher = data_val_matcher[data_val_matcher.user_id.isin(common_users)]\n",
    "data_train_ranker = data_train_ranker[data_train_ranker.user_id.isin(common_users)]\n",
    "data_val_ranker = data_val_ranker[data_val_ranker.user_id.isin(common_users)]\n",
    "\n",
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc3bbc1",
   "metadata": {},
   "source": [
    "**Baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9e561",
   "metadata": {},
   "source": [
    "Сделаем рекомендации методом случайного подбора и оценим их эффективность (precision_at_k). Данный результат будем считать базовым и пытаться его улучшить.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72fd5649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[1024306, 1102949, 6548453, 835394, 940804, 96...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        6  [1024306, 1102949, 6548453, 835394, 940804, 96..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eval_matcher = data_val_matcher.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_eval_matcher.columns=[USER_COL, ACTUAL_COL]\n",
    "result_eval_matcher.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4474e473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "      <th>random_recs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "      <td>[1047349, 5566855, 879143, 13876745, 998334, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[1024306, 1102949, 6548453, 835394, 940804, 96...</td>\n",
       "      <td>[7167441, 7142935, 896308, 838769, 13768063, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>[836281, 843306, 845294, 914190, 920456, 93886...</td>\n",
       "      <td>[6423857, 966832, 13417451, 1121393, 12171707,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual  \\\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...   \n",
       "1        6  [1024306, 1102949, 6548453, 835394, 940804, 96...   \n",
       "2        7  [836281, 843306, 845294, 914190, 920456, 93886...   \n",
       "\n",
       "                                         random_recs  \n",
       "0  [1047349, 5566855, 879143, 13876745, 998334, 1...  \n",
       "1  [7167441, 7142935, 896308, 838769, 13768063, 1...  \n",
       "2  [6423857, 966832, 13417451, 1121393, 12171707,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# список из всех возможных товаров\n",
    "all_items = list(data_val_matcher['item_id'].unique())\n",
    "# рекомендация для каждого юзера 5 случайных товаров\n",
    "random.seed(42)\n",
    "result_eval_matcher['random_recs'] = result_eval_matcher['user_id'].apply(lambda x: random.sample(all_items, N_PREDICT))\n",
    "result_eval_matcher.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadeb587",
   "metadata": {},
   "source": [
    "Посчитаем presicion at 5 для случайных рекомендаций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30be34ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('random_recs', 0.0027154046997389042)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOPK_PRECISION = 5\n",
    "sorted(calc_precision_at_k(result_eval_matcher, TOPK_PRECISION), key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205da2ee",
   "metadata": {},
   "source": [
    "Задача нашей модели - показать результат > 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe32181",
   "metadata": {},
   "source": [
    "**Построение модели первого уровня**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c64e00d",
   "metadata": {},
   "source": [
    "Попробуем посмотреть на качество результата модели первого уровня при различных весах в user-item матрице "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bff6b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Довольно долго просчитывает, результат описан в заметке ниже, можно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9e20a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = ['quantity', 'sales_value',\n",
    "           'log_quantity', 'log_sales_value',\n",
    "           'log_quantity+1', 'log_sales_value+1', 'boughten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a7944c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  quantity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9740ba0b0664e5aa12e19b46055882b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d240216f374f1785083e7e7d7c3045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  sales_value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d978b418ffc4955a7bdc287d0b75d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403d1cfa4c9347cb89159e41a638c102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  log_quantity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73755baf9f1c4ebda5785c2774c077a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ee2579a54a476089ca5789baca24a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  log_sales_value\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003d014bbe1c4bfb8b33c02eea52dcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fa28f462384f1d8faaf397a1942510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  log_quantity+1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5540c088be9040cda2b79822dd2baa52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99384c665a7f47f6a3b5b5afd9dfbacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  log_sales_value+1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0b8843b8494401aa03a2c02b30b1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0280e7864c04355982832b32fc7890b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  boughten\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efab8dd92e0f40c88291cff985482128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee9256e07334adcaa0ebbcdea1cbc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('own recs by quantity', 0.29838120104438465), ('own recs by sales_value', 0.29838120104438465), ('own recs by log_quantity', 0.29838120104438465), ('own recs by log_sales_value', 0.29838120104438465), ('own recs by log_quantity+1', 0.29838120104438465), ('own recs by log_sales_value+1', 0.29838120104438465), ('own recs by boughten', 0.29838120104438465), ('als recs by log_quantity', 0.1289817232375969), ('als recs by quantity', 0.12804177545691808), ('als recs by log_sales_value', 0.12720626631853682), ('als recs by sales_value', 0.12657963446475112), ('als recs by boughten', 0.12637075718015564), ('als recs by log_quantity+1', 0.1254308093994768), ('als recs by log_sales_value+1', 0.12375979112271432), ('random_recs', 0.0027154046997389042)]\n",
      "Wall time: 4min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for param in weights:\n",
    "    own_name = ['own recs by '+param]\n",
    "    als_name = ['als recs by '+param]\n",
    "    \n",
    "    #Создаем экземпляр класса\n",
    "    recommender = MainRecommender(data_train_matcher, weighting = True, param=param)\n",
    "    \n",
    "    #Делаем предсказания\n",
    "    result_eval_matcher[own_name] = result_eval_matcher['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N_PREDICT))\n",
    "    result_eval_matcher[als_name] = result_eval_matcher['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=N_PREDICT))\n",
    "      \n",
    "#Считаем score   \n",
    "TOPK_PRECISION = 5   \n",
    "print(sorted(calc_precision_at_k(result_eval_matcher, TOPK_PRECISION), key=lambda x: x[1],reverse=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf8f75",
   "metadata": {},
   "source": [
    "Как мы видим, переборка весов влияла на качество работы als модели, но не изменила качество own recs. \n",
    "Наилучший результат показала модель own recs. \n",
    "Ее результаты мы возьмем для работы модели уровня 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48af987",
   "metadata": {},
   "source": [
    "Переобучим экземпляр класса MainRecommender с необходимым параметром."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "304b5d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model using base param:  quantity\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c43cc7ba4e47d5ac91b43848c2d2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e42038dd1648648e1ca874447fb15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_matcher, weighting = True, param='quantity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bd32c5",
   "metadata": {},
   "source": [
    "**Подготовка данных для трейна**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1340afbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# взяли пользователей из трейна для ранжирования\n",
    "df_match_candidates = pd.DataFrame(data_train_ranker[USER_COL].unique())\n",
    "df_match_candidates.columns = [USER_COL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f569052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем кандитатов с первого этапа (matcher)\n",
    "df_match_candidates['candidates'] = df_match_candidates[USER_COL].apply(lambda x: recommender.get_own_recommendations(x, N=N_PREDICT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7619e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разворачиваем товары\n",
    "df_items = df_match_candidates.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "df_items.name = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "604fad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_match_candidates = df_match_candidates.drop('candidates', axis=1).join(df_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfacc72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>913210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>1029743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>5569374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>838186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id\n",
       "0     2070   913210\n",
       "0     2070  1029743\n",
       "0     2070  5569374\n",
       "0     2070   838186"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_match_candidates.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c65156d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_candidates\n",
      "Shape: (57450, 2) Users: 1915 Items: 3736\n"
     ]
    }
   ],
   "source": [
    "print_stats_data(df_match_candidates, 'match_candidates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e75aa",
   "metadata": {},
   "source": [
    "**Создаем трейн сет для ранжирования с учетом кандидатов с этапа 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fae1df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = data_train_ranker[[USER_COL, ITEM_COL]].copy()\n",
    "df_ranker_train['target'] = 1  # тут только покупки \n",
    "\n",
    "df_ranker_train = df_match_candidates.merge(df_ranker_train, on=[USER_COL, ITEM_COL], how='left')\n",
    "\n",
    "df_ranker_train['target'].fillna(0, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd4abb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21757623243096308"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_train['target'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216fe296",
   "metadata": {},
   "source": [
    "**Подготавливаем фичи для обучения модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed343cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>913210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>WATER - CARBONATED/FLVRD DRINK</td>\n",
       "      <td>NON-CRBNTD DRNKING/MNERAL WATE</td>\n",
       "      <td>405.6 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>U</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2070</td>\n",
       "      <td>1029743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>FLUID MILK PRODUCTS</td>\n",
       "      <td>FLUID MILK WHITE ONLY</td>\n",
       "      <td>1 GA</td>\n",
       "      <td>45-54</td>\n",
       "      <td>U</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  target manufacturer department     brand  \\\n",
       "0     2070   913210     1.0            2    GROCERY  National   \n",
       "1     2070  1029743     0.0           69    GROCERY   Private   \n",
       "\n",
       "                   commodity_desc              sub_commodity_desc  \\\n",
       "0  WATER - CARBONATED/FLVRD DRINK  NON-CRBNTD DRNKING/MNERAL WATE   \n",
       "1             FLUID MILK PRODUCTS           FLUID MILK WHITE ONLY   \n",
       "\n",
       "  curr_size_of_product age_desc marital_status_code income_desc  \\\n",
       "0             405.6 OZ    45-54                   U      50-74K   \n",
       "1                 1 GA    45-54                   U      50-74K   \n",
       "\n",
       "  homeowner_desc hh_comp_desc household_size_desc kid_category_desc  \n",
       "0        Unknown      Unknown                   1      None/Unknown  \n",
       "1        Unknown      Unknown                   1      None/Unknown  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_train = df_ranker_train.merge(item_features, on='item_id', how='left')\n",
    "df_ranker_train = df_ranker_train.merge(user_features, on='user_id', how='left')\n",
    "df_ranker_train['manufacturer'] = df_ranker_train['manufacturer'].astype(str)\n",
    "\n",
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a6ee18",
   "metadata": {},
   "source": [
    "Базовые фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93237ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('sales_value').sum().rename('total_item_sales_value'), how='left',on=ITEM_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('total_quantity_value'), how='left',on=ITEM_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg(USER_COL).count().rename('item_freq'), how='left',on=ITEM_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg(USER_COL).count().rename('user_freq'), how='left',on=USER_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg('sales_value').sum().rename('total_user_sales_value'), how='left',on=USER_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_week')/df_join_train_matcher.week_no.nunique(), how='left',on=ITEM_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg('quantity').sum().rename('user_quantity_per_week')/df_join_train_matcher.week_no.nunique(), how='left',on=USER_COL)\n",
    "\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg('quantity').sum().rename('item_quantity_per_basket')/df_join_train_matcher.basket_id.nunique(), how='left',on=ITEM_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg('quantity').sum().rename('user_quantity_per_baskter')/df_join_train_matcher.basket_id.nunique(), how='left',on=USER_COL)\n",
    "\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=ITEM_COL).agg(USER_COL).count().rename('item_freq_per_basket')/df_join_train_matcher.basket_id.nunique(), how='left',on=ITEM_COL)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(df_join_train_matcher.groupby(by=USER_COL).agg(USER_COL).count().rename('user_freq_per_basket')/df_join_train_matcher.basket_id.nunique(), how='left',on=USER_COL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35027e33",
   "metadata": {},
   "source": [
    "Дополнительные фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e09c4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний чек\n",
    "users_sales = data_train_ranker.groupby('user_id')['sales_value'].mean().reset_index()\n",
    "users_sales.rename(columns={'sales_value': 'avg_cheque'}, inplace=True)\n",
    "df_ranker_train = df_ranker_train.merge(users_sales[['user_id', 'avg_cheque']], on='user_id', how='left')\n",
    "\n",
    "# Средняя частота покупки\n",
    "users_sales = data_train_ranker.groupby('user_id')['quantity'].mean().reset_index()\n",
    "users_sales.rename(columns={'quantity': 'avg_quantity'}, inplace=True)\n",
    "df_ranker_train = df_ranker_train.merge(users_sales[['user_id', 'avg_quantity']], on='user_id', how='left')\n",
    "\n",
    "# Средная цена купленных товаров пользователем\n",
    "users_sales = data_train_ranker.groupby('user_id')[['sales_value', 'quantity']].sum().reset_index()\n",
    "users_sales['avg_price_by_user'] = users_sales['sales_value'] / users_sales['quantity']\n",
    "df_ranker_train = df_ranker_train.merge(users_sales[['user_id', 'avg_price_by_user']], on='user_id', how='left')\n",
    "\n",
    "# Средняя цена товаров\n",
    "items_sales = data_train_ranker.groupby('item_id')[['sales_value', 'quantity']].sum().reset_index()\n",
    "items_sales['avg_price_by_item'] = items_sales['sales_value'] / items_sales['quantity']\n",
    "items_sales['avg_price_by_item'].fillna(0, inplace=True)\n",
    "df_ranker_train = df_ranker_train.merge(items_sales[['item_id', 'avg_price_by_item']], on='item_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26796156",
   "metadata": {},
   "source": [
    "Еще больше фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df2be0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_item_features(user_data, item_data, result_df):\n",
    "    user_cols = list(user_data.select_dtypes(include=['object']).columns)\n",
    "    items_cols = item_data.columns.to_list()\n",
    "    \n",
    "    #Удаляем столбцы, содержащие id\n",
    "    del_cols = ['user_id', 'basket_id', 'item_id', 'store_id']\n",
    "    for el in del_cols:\n",
    "        items_cols.remove(el)\n",
    "        \n",
    "    #Генерируем суммы\n",
    "    for col in user_cols:\n",
    "        for c in items_cols:\n",
    "            name = str('sum'+' of '+c+' by '+col)\n",
    "            tmp_df = user_data.copy()\n",
    "            tmp_df = tmp_df.merge(item_data.groupby(USER_COL).agg(c).sum().rename(name), how='left', on=USER_COL)\n",
    "            tmp_df = tmp_df.groupby(by=col).sum().reset_index()\n",
    "            result_df=result_df.merge(tmp_df[[col, name]], how='left',on=col)\n",
    "            \n",
    "    #Генерируем ср. значения\n",
    "    for col in user_cols:\n",
    "        for c in items_cols:\n",
    "            name = str('mean'+' of '+c+' by '+col)\n",
    "            tmp_df = user_data.copy()\n",
    "            tmp_df = tmp_df.merge(item_data.groupby(USER_COL).agg(c).mean().rename(name), how='left', on=USER_COL)\n",
    "            tmp_df = tmp_df.groupby(by=col).mean().reset_index()\n",
    "            result_df=result_df.merge(tmp_df[[col, name]], how='left',on=col)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "968356da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features  213\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_ranker_train = generate_user_item_features(user_features, df_join_train_matcher, df_ranker_train)\n",
    "print('total features ', len(df_ranker_train.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6c38d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_item_item_features(user_data, item_data, result_df):\n",
    "    user_cols = list(user_data.select_dtypes(include=['object']).columns)\n",
    "    items_cols = item_data.columns.to_list()\n",
    "    \n",
    "    #Удаляем столбцы, содержащие id\n",
    "    del_cols = ['user_id', 'basket_id', 'item_id', 'store_id']\n",
    "    for el in del_cols:\n",
    "        items_cols.remove(el)\n",
    "        \n",
    "    #Генерируем суммы\n",
    "    for col in user_cols:\n",
    "        for c in items_cols:\n",
    "            name = str('sum'+' of '+c+' by '+col)\n",
    "            tmp_df = user_data.copy()\n",
    "            tmp_df = tmp_df.merge(item_data.groupby(ITEM_COL).agg(c).sum().rename(name), how='left', on=ITEM_COL)\n",
    "            tmp_df = tmp_df.groupby(by=col).sum().reset_index()\n",
    "            result_df=result_df.merge(tmp_df[[col, name]], how='left',on=col)\n",
    "            \n",
    "    #Генерируем ср. значения\n",
    "    for col in user_cols:\n",
    "        for c in items_cols:\n",
    "            name = str('mean'+' of '+c+' by '+col)\n",
    "            tmp_df = user_data.copy()\n",
    "            tmp_df = tmp_df.merge(item_data.groupby(ITEM_COL).agg(c).mean().rename(name), how='left', on=ITEM_COL)\n",
    "            tmp_df = tmp_df.groupby(by=col).mean().reset_index()\n",
    "            result_df=result_df.merge(tmp_df[[col, name]], how='left',on=col)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dfbac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features  343\n",
      "Wall time: 34.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_ranker_train = generate_item_item_features(item_features, df_join_train_matcher, df_ranker_train)\n",
    "print('total features ', len(df_ranker_train.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4619611d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'item_id',\n",
       " 'target',\n",
       " 'manufacturer',\n",
       " 'department',\n",
       " 'brand',\n",
       " 'commodity_desc',\n",
       " 'sub_commodity_desc',\n",
       " 'curr_size_of_product',\n",
       " 'age_desc',\n",
       " 'marital_status_code',\n",
       " 'income_desc',\n",
       " 'homeowner_desc',\n",
       " 'hh_comp_desc',\n",
       " 'household_size_desc',\n",
       " 'kid_category_desc',\n",
       " 'total_item_sales_value',\n",
       " 'total_quantity_value',\n",
       " 'item_freq',\n",
       " 'user_freq',\n",
       " 'total_user_sales_value',\n",
       " 'item_quantity_per_week',\n",
       " 'user_quantity_per_week',\n",
       " 'item_quantity_per_basket',\n",
       " 'user_quantity_per_baskter',\n",
       " 'item_freq_per_basket',\n",
       " 'user_freq_per_basket',\n",
       " 'avg_cheque',\n",
       " 'avg_quantity',\n",
       " 'avg_price_by_user',\n",
       " 'avg_price_by_item',\n",
       " 'sum of day by age_desc',\n",
       " 'sum of quantity by age_desc',\n",
       " 'sum of sales_value by age_desc',\n",
       " 'sum of retail_disc by age_desc',\n",
       " 'sum of trans_time by age_desc',\n",
       " 'sum of week_no by age_desc',\n",
       " 'sum of coupon_disc by age_desc',\n",
       " 'sum of coupon_match_disc by age_desc',\n",
       " 'sum of log_quantity by age_desc',\n",
       " 'sum of log_sales_value by age_desc',\n",
       " 'sum of log_quantity+1 by age_desc',\n",
       " 'sum of log_sales_value+1 by age_desc',\n",
       " 'sum of boughten by age_desc',\n",
       " 'sum of day by marital_status_code',\n",
       " 'sum of quantity by marital_status_code',\n",
       " 'sum of sales_value by marital_status_code',\n",
       " 'sum of retail_disc by marital_status_code',\n",
       " 'sum of trans_time by marital_status_code',\n",
       " 'sum of week_no by marital_status_code',\n",
       " 'sum of coupon_disc by marital_status_code',\n",
       " 'sum of coupon_match_disc by marital_status_code',\n",
       " 'sum of log_quantity by marital_status_code',\n",
       " 'sum of log_sales_value by marital_status_code',\n",
       " 'sum of log_quantity+1 by marital_status_code',\n",
       " 'sum of log_sales_value+1 by marital_status_code',\n",
       " 'sum of boughten by marital_status_code',\n",
       " 'sum of day by income_desc',\n",
       " 'sum of quantity by income_desc',\n",
       " 'sum of sales_value by income_desc',\n",
       " 'sum of retail_disc by income_desc',\n",
       " 'sum of trans_time by income_desc',\n",
       " 'sum of week_no by income_desc',\n",
       " 'sum of coupon_disc by income_desc',\n",
       " 'sum of coupon_match_disc by income_desc',\n",
       " 'sum of log_quantity by income_desc',\n",
       " 'sum of log_sales_value by income_desc',\n",
       " 'sum of log_quantity+1 by income_desc',\n",
       " 'sum of log_sales_value+1 by income_desc',\n",
       " 'sum of boughten by income_desc',\n",
       " 'sum of day by homeowner_desc',\n",
       " 'sum of quantity by homeowner_desc',\n",
       " 'sum of sales_value by homeowner_desc',\n",
       " 'sum of retail_disc by homeowner_desc',\n",
       " 'sum of trans_time by homeowner_desc',\n",
       " 'sum of week_no by homeowner_desc',\n",
       " 'sum of coupon_disc by homeowner_desc',\n",
       " 'sum of coupon_match_disc by homeowner_desc',\n",
       " 'sum of log_quantity by homeowner_desc',\n",
       " 'sum of log_sales_value by homeowner_desc',\n",
       " 'sum of log_quantity+1 by homeowner_desc',\n",
       " 'sum of log_sales_value+1 by homeowner_desc',\n",
       " 'sum of boughten by homeowner_desc',\n",
       " 'sum of day by hh_comp_desc',\n",
       " 'sum of quantity by hh_comp_desc',\n",
       " 'sum of sales_value by hh_comp_desc',\n",
       " 'sum of retail_disc by hh_comp_desc',\n",
       " 'sum of trans_time by hh_comp_desc',\n",
       " 'sum of week_no by hh_comp_desc',\n",
       " 'sum of coupon_disc by hh_comp_desc',\n",
       " 'sum of coupon_match_disc by hh_comp_desc',\n",
       " 'sum of log_quantity by hh_comp_desc',\n",
       " 'sum of log_sales_value by hh_comp_desc',\n",
       " 'sum of log_quantity+1 by hh_comp_desc',\n",
       " 'sum of log_sales_value+1 by hh_comp_desc',\n",
       " 'sum of boughten by hh_comp_desc',\n",
       " 'sum of day by household_size_desc',\n",
       " 'sum of quantity by household_size_desc',\n",
       " 'sum of sales_value by household_size_desc',\n",
       " 'sum of retail_disc by household_size_desc',\n",
       " 'sum of trans_time by household_size_desc',\n",
       " 'sum of week_no by household_size_desc',\n",
       " 'sum of coupon_disc by household_size_desc',\n",
       " 'sum of coupon_match_disc by household_size_desc',\n",
       " 'sum of log_quantity by household_size_desc',\n",
       " 'sum of log_sales_value by household_size_desc',\n",
       " 'sum of log_quantity+1 by household_size_desc',\n",
       " 'sum of log_sales_value+1 by household_size_desc',\n",
       " 'sum of boughten by household_size_desc',\n",
       " 'sum of day by kid_category_desc',\n",
       " 'sum of quantity by kid_category_desc',\n",
       " 'sum of sales_value by kid_category_desc',\n",
       " 'sum of retail_disc by kid_category_desc',\n",
       " 'sum of trans_time by kid_category_desc',\n",
       " 'sum of week_no by kid_category_desc',\n",
       " 'sum of coupon_disc by kid_category_desc',\n",
       " 'sum of coupon_match_disc by kid_category_desc',\n",
       " 'sum of log_quantity by kid_category_desc',\n",
       " 'sum of log_sales_value by kid_category_desc',\n",
       " 'sum of log_quantity+1 by kid_category_desc',\n",
       " 'sum of log_sales_value+1 by kid_category_desc',\n",
       " 'sum of boughten by kid_category_desc',\n",
       " 'mean of day by age_desc',\n",
       " 'mean of quantity by age_desc',\n",
       " 'mean of sales_value by age_desc',\n",
       " 'mean of retail_disc by age_desc',\n",
       " 'mean of trans_time by age_desc',\n",
       " 'mean of week_no by age_desc',\n",
       " 'mean of coupon_disc by age_desc',\n",
       " 'mean of coupon_match_disc by age_desc',\n",
       " 'mean of log_quantity by age_desc',\n",
       " 'mean of log_sales_value by age_desc',\n",
       " 'mean of log_quantity+1 by age_desc',\n",
       " 'mean of log_sales_value+1 by age_desc',\n",
       " 'mean of boughten by age_desc',\n",
       " 'mean of day by marital_status_code',\n",
       " 'mean of quantity by marital_status_code',\n",
       " 'mean of sales_value by marital_status_code',\n",
       " 'mean of retail_disc by marital_status_code',\n",
       " 'mean of trans_time by marital_status_code',\n",
       " 'mean of week_no by marital_status_code',\n",
       " 'mean of coupon_disc by marital_status_code',\n",
       " 'mean of coupon_match_disc by marital_status_code',\n",
       " 'mean of log_quantity by marital_status_code',\n",
       " 'mean of log_sales_value by marital_status_code',\n",
       " 'mean of log_quantity+1 by marital_status_code',\n",
       " 'mean of log_sales_value+1 by marital_status_code',\n",
       " 'mean of boughten by marital_status_code',\n",
       " 'mean of day by income_desc',\n",
       " 'mean of quantity by income_desc',\n",
       " 'mean of sales_value by income_desc',\n",
       " 'mean of retail_disc by income_desc',\n",
       " 'mean of trans_time by income_desc',\n",
       " 'mean of week_no by income_desc',\n",
       " 'mean of coupon_disc by income_desc',\n",
       " 'mean of coupon_match_disc by income_desc',\n",
       " 'mean of log_quantity by income_desc',\n",
       " 'mean of log_sales_value by income_desc',\n",
       " 'mean of log_quantity+1 by income_desc',\n",
       " 'mean of log_sales_value+1 by income_desc',\n",
       " 'mean of boughten by income_desc',\n",
       " 'mean of day by homeowner_desc',\n",
       " 'mean of quantity by homeowner_desc',\n",
       " 'mean of sales_value by homeowner_desc',\n",
       " 'mean of retail_disc by homeowner_desc',\n",
       " 'mean of trans_time by homeowner_desc',\n",
       " 'mean of week_no by homeowner_desc',\n",
       " 'mean of coupon_disc by homeowner_desc',\n",
       " 'mean of coupon_match_disc by homeowner_desc',\n",
       " 'mean of log_quantity by homeowner_desc',\n",
       " 'mean of log_sales_value by homeowner_desc',\n",
       " 'mean of log_quantity+1 by homeowner_desc',\n",
       " 'mean of log_sales_value+1 by homeowner_desc',\n",
       " 'mean of boughten by homeowner_desc',\n",
       " 'mean of day by hh_comp_desc',\n",
       " 'mean of quantity by hh_comp_desc',\n",
       " 'mean of sales_value by hh_comp_desc',\n",
       " 'mean of retail_disc by hh_comp_desc',\n",
       " 'mean of trans_time by hh_comp_desc',\n",
       " 'mean of week_no by hh_comp_desc',\n",
       " 'mean of coupon_disc by hh_comp_desc',\n",
       " 'mean of coupon_match_disc by hh_comp_desc',\n",
       " 'mean of log_quantity by hh_comp_desc',\n",
       " 'mean of log_sales_value by hh_comp_desc',\n",
       " 'mean of log_quantity+1 by hh_comp_desc',\n",
       " 'mean of log_sales_value+1 by hh_comp_desc',\n",
       " 'mean of boughten by hh_comp_desc',\n",
       " 'mean of day by household_size_desc',\n",
       " 'mean of quantity by household_size_desc',\n",
       " 'mean of sales_value by household_size_desc',\n",
       " 'mean of retail_disc by household_size_desc',\n",
       " 'mean of trans_time by household_size_desc',\n",
       " 'mean of week_no by household_size_desc',\n",
       " 'mean of coupon_disc by household_size_desc',\n",
       " 'mean of coupon_match_disc by household_size_desc',\n",
       " 'mean of log_quantity by household_size_desc',\n",
       " 'mean of log_sales_value by household_size_desc',\n",
       " 'mean of log_quantity+1 by household_size_desc',\n",
       " 'mean of log_sales_value+1 by household_size_desc',\n",
       " 'mean of boughten by household_size_desc',\n",
       " 'mean of day by kid_category_desc',\n",
       " 'mean of quantity by kid_category_desc',\n",
       " 'mean of sales_value by kid_category_desc',\n",
       " 'mean of retail_disc by kid_category_desc',\n",
       " 'mean of trans_time by kid_category_desc',\n",
       " 'mean of week_no by kid_category_desc',\n",
       " 'mean of coupon_disc by kid_category_desc',\n",
       " 'mean of coupon_match_disc by kid_category_desc',\n",
       " 'mean of log_quantity by kid_category_desc',\n",
       " 'mean of log_sales_value by kid_category_desc',\n",
       " 'mean of log_quantity+1 by kid_category_desc',\n",
       " 'mean of log_sales_value+1 by kid_category_desc',\n",
       " 'mean of boughten by kid_category_desc',\n",
       " 'sum of day by department',\n",
       " 'sum of quantity by department',\n",
       " 'sum of sales_value by department',\n",
       " 'sum of retail_disc by department',\n",
       " 'sum of trans_time by department',\n",
       " 'sum of week_no by department',\n",
       " 'sum of coupon_disc by department',\n",
       " 'sum of coupon_match_disc by department',\n",
       " 'sum of log_quantity by department',\n",
       " 'sum of log_sales_value by department',\n",
       " 'sum of log_quantity+1 by department',\n",
       " 'sum of log_sales_value+1 by department',\n",
       " 'sum of boughten by department',\n",
       " 'sum of day by brand',\n",
       " 'sum of quantity by brand',\n",
       " 'sum of sales_value by brand',\n",
       " 'sum of retail_disc by brand',\n",
       " 'sum of trans_time by brand',\n",
       " 'sum of week_no by brand',\n",
       " 'sum of coupon_disc by brand',\n",
       " 'sum of coupon_match_disc by brand',\n",
       " 'sum of log_quantity by brand',\n",
       " 'sum of log_sales_value by brand',\n",
       " 'sum of log_quantity+1 by brand',\n",
       " 'sum of log_sales_value+1 by brand',\n",
       " 'sum of boughten by brand',\n",
       " 'sum of day by commodity_desc',\n",
       " 'sum of quantity by commodity_desc',\n",
       " 'sum of sales_value by commodity_desc',\n",
       " 'sum of retail_disc by commodity_desc',\n",
       " 'sum of trans_time by commodity_desc',\n",
       " 'sum of week_no by commodity_desc',\n",
       " 'sum of coupon_disc by commodity_desc',\n",
       " 'sum of coupon_match_disc by commodity_desc',\n",
       " 'sum of log_quantity by commodity_desc',\n",
       " 'sum of log_sales_value by commodity_desc',\n",
       " 'sum of log_quantity+1 by commodity_desc',\n",
       " 'sum of log_sales_value+1 by commodity_desc',\n",
       " 'sum of boughten by commodity_desc',\n",
       " 'sum of day by sub_commodity_desc',\n",
       " 'sum of quantity by sub_commodity_desc',\n",
       " 'sum of sales_value by sub_commodity_desc',\n",
       " 'sum of retail_disc by sub_commodity_desc',\n",
       " 'sum of trans_time by sub_commodity_desc',\n",
       " 'sum of week_no by sub_commodity_desc',\n",
       " 'sum of coupon_disc by sub_commodity_desc',\n",
       " 'sum of coupon_match_disc by sub_commodity_desc',\n",
       " 'sum of log_quantity by sub_commodity_desc',\n",
       " 'sum of log_sales_value by sub_commodity_desc',\n",
       " 'sum of log_quantity+1 by sub_commodity_desc',\n",
       " 'sum of log_sales_value+1 by sub_commodity_desc',\n",
       " 'sum of boughten by sub_commodity_desc',\n",
       " 'sum of day by curr_size_of_product',\n",
       " 'sum of quantity by curr_size_of_product',\n",
       " 'sum of sales_value by curr_size_of_product',\n",
       " 'sum of retail_disc by curr_size_of_product',\n",
       " 'sum of trans_time by curr_size_of_product',\n",
       " 'sum of week_no by curr_size_of_product',\n",
       " 'sum of coupon_disc by curr_size_of_product',\n",
       " 'sum of coupon_match_disc by curr_size_of_product',\n",
       " 'sum of log_quantity by curr_size_of_product',\n",
       " 'sum of log_sales_value by curr_size_of_product',\n",
       " 'sum of log_quantity+1 by curr_size_of_product',\n",
       " 'sum of log_sales_value+1 by curr_size_of_product',\n",
       " 'sum of boughten by curr_size_of_product',\n",
       " 'mean of day by department',\n",
       " 'mean of quantity by department',\n",
       " 'mean of sales_value by department',\n",
       " 'mean of retail_disc by department',\n",
       " 'mean of trans_time by department',\n",
       " 'mean of week_no by department',\n",
       " 'mean of coupon_disc by department',\n",
       " 'mean of coupon_match_disc by department',\n",
       " 'mean of log_quantity by department',\n",
       " 'mean of log_sales_value by department',\n",
       " 'mean of log_quantity+1 by department',\n",
       " 'mean of log_sales_value+1 by department',\n",
       " 'mean of boughten by department',\n",
       " 'mean of day by brand',\n",
       " 'mean of quantity by brand',\n",
       " 'mean of sales_value by brand',\n",
       " 'mean of retail_disc by brand',\n",
       " 'mean of trans_time by brand',\n",
       " 'mean of week_no by brand',\n",
       " 'mean of coupon_disc by brand',\n",
       " 'mean of coupon_match_disc by brand',\n",
       " 'mean of log_quantity by brand',\n",
       " 'mean of log_sales_value by brand',\n",
       " 'mean of log_quantity+1 by brand',\n",
       " 'mean of log_sales_value+1 by brand',\n",
       " 'mean of boughten by brand',\n",
       " 'mean of day by commodity_desc',\n",
       " 'mean of quantity by commodity_desc',\n",
       " 'mean of sales_value by commodity_desc',\n",
       " 'mean of retail_disc by commodity_desc',\n",
       " 'mean of trans_time by commodity_desc',\n",
       " 'mean of week_no by commodity_desc',\n",
       " 'mean of coupon_disc by commodity_desc',\n",
       " 'mean of coupon_match_disc by commodity_desc',\n",
       " 'mean of log_quantity by commodity_desc',\n",
       " 'mean of log_sales_value by commodity_desc',\n",
       " 'mean of log_quantity+1 by commodity_desc',\n",
       " 'mean of log_sales_value+1 by commodity_desc',\n",
       " 'mean of boughten by commodity_desc',\n",
       " 'mean of day by sub_commodity_desc',\n",
       " 'mean of quantity by sub_commodity_desc',\n",
       " 'mean of sales_value by sub_commodity_desc',\n",
       " 'mean of retail_disc by sub_commodity_desc',\n",
       " 'mean of trans_time by sub_commodity_desc',\n",
       " 'mean of week_no by sub_commodity_desc',\n",
       " 'mean of coupon_disc by sub_commodity_desc',\n",
       " 'mean of coupon_match_disc by sub_commodity_desc',\n",
       " 'mean of log_quantity by sub_commodity_desc',\n",
       " 'mean of log_sales_value by sub_commodity_desc',\n",
       " 'mean of log_quantity+1 by sub_commodity_desc',\n",
       " 'mean of log_sales_value+1 by sub_commodity_desc',\n",
       " 'mean of boughten by sub_commodity_desc',\n",
       " 'mean of day by curr_size_of_product',\n",
       " 'mean of quantity by curr_size_of_product',\n",
       " 'mean of sales_value by curr_size_of_product',\n",
       " 'mean of retail_disc by curr_size_of_product',\n",
       " 'mean of trans_time by curr_size_of_product',\n",
       " 'mean of week_no by curr_size_of_product',\n",
       " 'mean of coupon_disc by curr_size_of_product',\n",
       " 'mean of coupon_match_disc by curr_size_of_product',\n",
       " 'mean of log_quantity by curr_size_of_product',\n",
       " 'mean of log_sales_value by curr_size_of_product',\n",
       " 'mean of log_quantity+1 by curr_size_of_product',\n",
       " 'mean of log_sales_value+1 by curr_size_of_product',\n",
       " 'mean of boughten by curr_size_of_product']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184334a1",
   "metadata": {},
   "source": [
    "**Обучаем модель второго уровня**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34a87f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ranker_train.drop(columns = ['target'])\n",
    "y_train = df_ranker_train[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be5a3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[2:].tolist()\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b1877d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb = LGBMClassifier(objective='binary',\n",
    "                     max_depth=10, \n",
    "                     n_estimators=700, \n",
    "                     learning_rate=0.2,\n",
    "                     categorical_column=cat_feats)\n",
    "\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "train_preds = lgb.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db949a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict = df_ranker_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe2ee159",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict['proba_item_purchase'] = train_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e26f1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>target</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>...</th>\n",
       "      <th>mean of trans_time by curr_size_of_product</th>\n",
       "      <th>mean of week_no by curr_size_of_product</th>\n",
       "      <th>mean of coupon_disc by curr_size_of_product</th>\n",
       "      <th>mean of coupon_match_disc by curr_size_of_product</th>\n",
       "      <th>mean of log_quantity by curr_size_of_product</th>\n",
       "      <th>mean of log_sales_value by curr_size_of_product</th>\n",
       "      <th>mean of log_quantity+1 by curr_size_of_product</th>\n",
       "      <th>mean of log_sales_value+1 by curr_size_of_product</th>\n",
       "      <th>mean of boughten by curr_size_of_product</th>\n",
       "      <th>proba_item_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2070</td>\n",
       "      <td>913210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>WATER - CARBONATED/FLVRD DRINK</td>\n",
       "      <td>NON-CRBNTD DRNKING/MNERAL WATE</td>\n",
       "      <td>405.6 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>1537.442842</td>\n",
       "      <td>45.815940</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.742544</td>\n",
       "      <td>1.789636</td>\n",
       "      <td>0.997466</td>\n",
       "      <td>0.966736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2070</td>\n",
       "      <td>1029743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>Private</td>\n",
       "      <td>FLUID MILK PRODUCTS</td>\n",
       "      <td>FLUID MILK WHITE ONLY</td>\n",
       "      <td>1 GA</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>1630.974740</td>\n",
       "      <td>49.090432</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>-7.067626e-07</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.764696</td>\n",
       "      <td>1.168223</td>\n",
       "      <td>0.999724</td>\n",
       "      <td>0.133192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2070</td>\n",
       "      <td>5569374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1208</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>SOFT DRINKS</td>\n",
       "      <td>SOFT DRINKS 12/18&amp;15PK CAN CAR</td>\n",
       "      <td>12 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>1565.781241</td>\n",
       "      <td>48.956838</td>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-2.193967e-03</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.750705</td>\n",
       "      <td>1.432868</td>\n",
       "      <td>0.995978</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2070</td>\n",
       "      <td>838186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1790</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>BAKED SWEET GOODS</td>\n",
       "      <td>SW GDS:DONUTS</td>\n",
       "      <td>18.2 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>1567.599722</td>\n",
       "      <td>38.780708</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.729807</td>\n",
       "      <td>1.482357</td>\n",
       "      <td>0.999869</td>\n",
       "      <td>0.949918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2070</td>\n",
       "      <td>926905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>SOFT DRINKS</td>\n",
       "      <td>SOFT DRINKS 12/18&amp;15PK CAN CAR</td>\n",
       "      <td>12 OZ</td>\n",
       "      <td>45-54</td>\n",
       "      <td>...</td>\n",
       "      <td>1565.781241</td>\n",
       "      <td>48.956838</td>\n",
       "      <td>-0.015155</td>\n",
       "      <td>-2.193967e-03</td>\n",
       "      <td>-inf</td>\n",
       "      <td>-inf</td>\n",
       "      <td>0.750705</td>\n",
       "      <td>1.432868</td>\n",
       "      <td>0.995978</td>\n",
       "      <td>0.006468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 344 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  target manufacturer department     brand  \\\n",
       "0     2070   913210     1.0            2    GROCERY  National   \n",
       "1     2070  1029743     0.0           69    GROCERY   Private   \n",
       "2     2070  5569374     0.0         1208    GROCERY  National   \n",
       "3     2070   838186     1.0         1790    GROCERY  National   \n",
       "4     2070   926905     0.0          103    GROCERY  National   \n",
       "\n",
       "                   commodity_desc              sub_commodity_desc  \\\n",
       "0  WATER - CARBONATED/FLVRD DRINK  NON-CRBNTD DRNKING/MNERAL WATE   \n",
       "1             FLUID MILK PRODUCTS           FLUID MILK WHITE ONLY   \n",
       "2                     SOFT DRINKS  SOFT DRINKS 12/18&15PK CAN CAR   \n",
       "3               BAKED SWEET GOODS                   SW GDS:DONUTS   \n",
       "4                     SOFT DRINKS  SOFT DRINKS 12/18&15PK CAN CAR   \n",
       "\n",
       "  curr_size_of_product age_desc  ...  \\\n",
       "0             405.6 OZ    45-54  ...   \n",
       "1                 1 GA    45-54  ...   \n",
       "2                12 OZ    45-54  ...   \n",
       "3              18.2 OZ    45-54  ...   \n",
       "4                12 OZ    45-54  ...   \n",
       "\n",
       "  mean of trans_time by curr_size_of_product  \\\n",
       "0                                1537.442842   \n",
       "1                                1630.974740   \n",
       "2                                1565.781241   \n",
       "3                                1567.599722   \n",
       "4                                1565.781241   \n",
       "\n",
       "  mean of week_no by curr_size_of_product  \\\n",
       "0                               45.815940   \n",
       "1                               49.090432   \n",
       "2                               48.956838   \n",
       "3                               38.780708   \n",
       "4                               48.956838   \n",
       "\n",
       "  mean of coupon_disc by curr_size_of_product  \\\n",
       "0                                   -0.000899   \n",
       "1                                   -0.001173   \n",
       "2                                   -0.015155   \n",
       "3                                   -0.003247   \n",
       "4                                   -0.015155   \n",
       "\n",
       "  mean of coupon_match_disc by curr_size_of_product  \\\n",
       "0                                      0.000000e+00   \n",
       "1                                     -7.067626e-07   \n",
       "2                                     -2.193967e-03   \n",
       "3                                      0.000000e+00   \n",
       "4                                     -2.193967e-03   \n",
       "\n",
       "  mean of log_quantity by curr_size_of_product  \\\n",
       "0                                         -inf   \n",
       "1                                         -inf   \n",
       "2                                         -inf   \n",
       "3                                         -inf   \n",
       "4                                         -inf   \n",
       "\n",
       "  mean of log_sales_value by curr_size_of_product  \\\n",
       "0                                            -inf   \n",
       "1                                            -inf   \n",
       "2                                            -inf   \n",
       "3                                            -inf   \n",
       "4                                            -inf   \n",
       "\n",
       "   mean of log_quantity+1 by curr_size_of_product  \\\n",
       "0                                        0.742544   \n",
       "1                                        0.764696   \n",
       "2                                        0.750705   \n",
       "3                                        0.729807   \n",
       "4                                        0.750705   \n",
       "\n",
       "   mean of log_sales_value+1 by curr_size_of_product  \\\n",
       "0                                           1.789636   \n",
       "1                                           1.168223   \n",
       "2                                           1.432868   \n",
       "3                                           1.482357   \n",
       "4                                           1.432868   \n",
       "\n",
       "   mean of boughten by curr_size_of_product  proba_item_purchase  \n",
       "0                                  0.997466             0.966736  \n",
       "1                                  0.999724             0.133192  \n",
       "2                                  0.995978             0.005535  \n",
       "3                                  0.999869             0.949918  \n",
       "4                                  0.995978             0.006468  \n",
       "\n",
       "[5 rows x 344 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranker_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02abedd6",
   "metadata": {},
   "source": [
    "**Сделаем предсказания на тесте**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e62148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[821867, 834484, 856942, 865456, 889248, 90795...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[920308, 926804, 946489, 1006718, 1017061, 107...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [821867, 834484, 856942, 865456, 889248, 90795...\n",
       "1        6  [920308, 926804, 946489, 1006718, 1017061, 107..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eval_ranker = data_val_ranker.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_eval_ranker.columns=[USER_COL, ACTUAL_COL]\n",
    "result_eval_ranker.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "303a4ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_eval_ranker['own_rec'] = result_eval_ranker[USER_COL].apply(lambda x: recommender.get_own_recommendations(x, N=N_PREDICT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c259d641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('own_rec', 0.24689295039164288)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# померяем precision только модели матчинга, чтобы понимать влияение ранжирования на метрики\n",
    "sorted(calc_precision_at_k(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4893f7",
   "metadata": {},
   "source": [
    "Сделаем предсказания с учетом ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19255413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def rerank(user_id):\n",
    "    res = df_ranker_predict[df_ranker_predict[USER_COL]==user_id].sort_values('proba_item_purchase', ascending=False).head(N_PREDICT).item_id.tolist()\n",
    "    # Делаем постфильтрацию, оставляя только уникальные значения\n",
    "    res = list(OrderedDict.fromkeys(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73273dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_ranker['reranked_own_rec'] = result_eval_ranker[USER_COL].apply(lambda user_id: rerank(user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4dceb2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reranked_own_rec', 0.2920104438642282), ('own_rec', 0.24689295039164288)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calc_precision_at_k(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "743fbbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2958"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.2958"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129efdfe",
   "metadata": {},
   "source": [
    "Модель второго уровня показала результат лучше, чем модель первого уровня."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d0b135",
   "metadata": {},
   "source": [
    "**Оценка на тесте для выполнения курсового проекта**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aebfb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('retail_test1.csv')\n",
    "df_transactions = pd.read_csv('retail_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "298a88bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1340</td>\n",
       "      <td>41652823310</td>\n",
       "      <td>664</td>\n",
       "      <td>912987</td>\n",
       "      <td>1</td>\n",
       "      <td>8.49</td>\n",
       "      <td>446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>588</td>\n",
       "      <td>41652838477</td>\n",
       "      <td>664</td>\n",
       "      <td>1024426</td>\n",
       "      <td>1</td>\n",
       "      <td>6.29</td>\n",
       "      <td>388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2070</td>\n",
       "      <td>41652857291</td>\n",
       "      <td>664</td>\n",
       "      <td>995242</td>\n",
       "      <td>5</td>\n",
       "      <td>9.10</td>\n",
       "      <td>311</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>46</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1602</td>\n",
       "      <td>41665647035</td>\n",
       "      <td>664</td>\n",
       "      <td>827939</td>\n",
       "      <td>1</td>\n",
       "      <td>7.99</td>\n",
       "      <td>334</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1741</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1602</td>\n",
       "      <td>41665647035</td>\n",
       "      <td>664</td>\n",
       "      <td>927712</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>334</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1741</td>\n",
       "      <td>96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     1340  41652823310  664   912987         1         8.49       446   \n",
       "1      588  41652838477  664  1024426         1         6.29       388   \n",
       "2     2070  41652857291  664   995242         5         9.10       311   \n",
       "3     1602  41665647035  664   827939         1         7.99       334   \n",
       "4     1602  41665647035  664   927712         1         0.59       334   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0          0.0          52       96          0.0                0.0  \n",
       "1          0.0           8       96          0.0                0.0  \n",
       "2         -0.6          46       96          0.0                0.0  \n",
       "3          0.0        1741       96          0.0                0.0  \n",
       "4         -0.4        1741       96          0.0                0.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "570c9783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[880007, 883616, 931136, 938004, 940947, 94726...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[820165, 820291, 826784, 826835, 829009, 85784...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [880007, 883616, 931136, 938004, 940947, 94726...\n",
       "1        2  [820165, 820291, 826784, 826835, 829009, 85784..."
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test = df_test.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_test.columns=[USER_COL, ACTUAL_COL]\n",
    "result_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f92d98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test['own_rec'] = result_test[USER_COL].apply(lambda x: recommender.get_own_recommendations(x, N=N_PREDICT))\n",
    "result_test['reranked_own_rec'] = result_test[USER_COL].apply(lambda user_id: rerank(user_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f19ee",
   "metadata": {},
   "source": [
    "**Постфильтрация результатов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1ac77",
   "metadata": {},
   "source": [
    "Проверим, есть ли строки где количество предсказаний <5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8e384c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "# Проверим, есть ли строки где количество предсказаний <5\n",
    "nums = []\n",
    "for num, row in enumerate(result_test['reranked_own_rec']): \n",
    "    if len(row) < 5:\n",
    "        nums.append(num)\n",
    "print(len(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508b0eb",
   "metadata": {},
   "source": [
    "224 строки содержат меньше 5-ти предсказаний. Дозаполним пропуски из списка top-purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ba8f404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "top_recommends = recommender.top_purchases\n",
    "users = top_recommends['user_id'].to_list()\n",
    "top_list = top_recommends['item_id'].to_list()[:20]\n",
    "\n",
    "for num, row in result_test.iterrows(): \n",
    "    if num in nums:\n",
    "        if row.user_id in users:\n",
    "            rec_qty = 5 - len(row.reranked_own_rec)\n",
    "            new_rec = top_recommends[top_recommends['user_id']==row.user_id]['item_id'].head(rec_qty).to_list()\n",
    "            for rec in new_recs:\n",
    "                row.reranked_own_rec.append(rec)\n",
    "        else:\n",
    "            rec_qty = 5 - len(row.reranked_own_rec)\n",
    "            new_recs = random.sample(top_list, rec_qty)\n",
    "            for rec in new_recs:\n",
    "                row.reranked_own_rec.append(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de225253",
   "metadata": {},
   "source": [
    "Проверим, есть ли строки где количество предсказаний >5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "78f29cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1660\n"
     ]
    }
   ],
   "source": [
    "# Проверим, есть ли строки где количество предсказаний > 5\n",
    "nums = []\n",
    "for num, row in enumerate(result_test['reranked_own_rec']): \n",
    "    if len(row) > 5:\n",
    "        nums.append(num)\n",
    "print(len(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20cee3e",
   "metadata": {},
   "source": [
    "1660 строк содержат больше 5-ти предсказаний, оставим только ТОП-5 из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e7487b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, row in enumerate(result_test['reranked_own_rec']): \n",
    "    if num in nums:\n",
    "        result_test.at[num, 'reranked_own_rec'] = row[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6beef2",
   "metadata": {},
   "source": [
    "Проверим, остались ли в датасете предсказания длиной != 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c66e85c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "nums = []\n",
    "for num, row in enumerate(result_test['reranked_own_rec']): \n",
    "    if len(row) != 5:\n",
    "        nums.append(num)\n",
    "print(len(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08de000",
   "metadata": {},
   "source": [
    "Оценим качество наших предсказаний на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a57d8e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reranked_own_rec', 0.21708222811670896), ('own_rec', 0.1969230769230747)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(calc_precision_at_k(result_test, TOPK_PRECISION), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cfb7ab",
   "metadata": {},
   "source": [
    "Полученный результат на тесте: **presicion_at_5 = 0.2170**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6917c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним рекомендации\n",
    "recommendations = result_test[[USER_COL, 'reranked_own_rec']]\n",
    "recommendations.rename(columns = {'reranked_own_rec' : 'recommendations'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7192770d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[940947, 9297615, 9655212, 10149640, 856942]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[939860, 977374, 1097398, 1029743, 1074333]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[8020166, 939860, 986912, 6632283, 1029743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[1024306, 1098844, 6548453, 878996, 1029743]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[1122358, 993638, 1106523, 1126899, 862682]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>2496</td>\n",
       "      <td>[1056509, 1106523, 1041796, 907631, 916122]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>2497</td>\n",
       "      <td>[1029743, 1135834, 1051323, 1040807, 5590613]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>2498</td>\n",
       "      <td>[1106523, 1070820, 1100379, 1126899, 1130858]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>2499</td>\n",
       "      <td>[5569327, 5568378, 1070820, 1060872, 899624]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>2500</td>\n",
       "      <td>[1065538, 854405, 1056509, 1019643, 1126899]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1885 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                recommendations\n",
       "0           1   [940947, 9297615, 9655212, 10149640, 856942]\n",
       "1           2    [939860, 977374, 1097398, 1029743, 1074333]\n",
       "2           3    [8020166, 939860, 986912, 6632283, 1029743]\n",
       "3           6   [1024306, 1098844, 6548453, 878996, 1029743]\n",
       "4           7    [1122358, 993638, 1106523, 1126899, 862682]\n",
       "...       ...                                            ...\n",
       "1880     2496    [1056509, 1106523, 1041796, 907631, 916122]\n",
       "1881     2497  [1029743, 1135834, 1051323, 1040807, 5590613]\n",
       "1882     2498  [1106523, 1070820, 1100379, 1126899, 1130858]\n",
       "1883     2499   [5569327, 5568378, 1070820, 1060872, 899624]\n",
       "1884     2500   [1065538, 854405, 1056509, 1019643, 1126899]\n",
       "\n",
       "[1885 rows x 2 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2c54e1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[940947, 9297615, 9655212, 10149640, 856942]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[939860, 977374, 1097398, 1029743, 1074333]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                               recommendations\n",
       "0        1  [940947, 9297615, 9655212, 10149640, 856942]\n",
       "1        2   [939860, 977374, 1097398, 1029743, 1074333]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.to_csv('recommendations.csv', index=False)\n",
    "recommendations.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
